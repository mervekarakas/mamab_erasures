{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoke Test\n",
    "Quick sanity check that all algorithms run without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath('.')), ''))\n",
    "# When running from notebooks/ directory, add parent to path\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n",
    "import numpy as np\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'NumPy: {np.__version__}')\n",
    "print(f'CWD: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from models import (\n    BatchSP2, BatchSP2Erasure, BatchTPG, BatchTPGNew,\n    BatchSP2Simplified, BatchSP2RRR, BatchSGreedy, BatchTPGOld,\n    calculate_repetitions, init_bandit,\n    FEEDBACK_NONE, FEEDBACK_BEACON, FEEDBACK_ACK_SUCCESS,\n)\nfrom runners import run_episodes_with_same_erasures\nfrom utils import generate_erasure_sequence_multi\nprint('All imports OK')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unit test: single algorithm instantiation + run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal config\n",
    "K, M, T = 5, 3, 500\n",
    "eps = np.array([0.3, 0.7, 0.95])\n",
    "alphas = calculate_repetitions(eps, T, m=M)\n",
    "mu = [0.9, 0.5, 0.3, 0.1, 0.7]\n",
    "seq = generate_erasure_sequence_multi(T, M, eps)\n",
    "print(f'alphas = {alphas}')\n",
    "print(f'erasure_seq shape = {seq.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SP2 (no feedback baseline)\n",
    "sp2 = BatchSP2(K, M, T, alphas, mu=mu, epsilon=eps,\n",
    "               erasure_seq=seq, feedback_mode=FEEDBACK_NONE)\n",
    "sp2.run()\n",
    "reg_sp2 = np.cumsum(np.sum(sp2.regrets, axis=1))[-1]\n",
    "print(f'SP2 final regret: {reg_sp2:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SP2-Feedback (ACK on success)\n",
    "sp2fb = BatchSP2Erasure(K, M, T, alphas, mu=mu, epsilon=eps,\n",
    "                        erasure_seq=seq, feedback_mode=FEEDBACK_ACK_SUCCESS)\n",
    "sp2fb.run()\n",
    "reg_sp2fb = np.cumsum(np.sum(sp2fb.regrets, axis=1))[-1]\n",
    "print(f'SP2-Feedback final regret: {reg_sp2fb:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TPG (ACK on success)\n",
    "tpg = BatchTPG(K, M, T, alphas, mu=mu, epsilon=eps,\n",
    "               erasure_seq=seq, feedback_mode=FEEDBACK_ACK_SUCCESS)\n",
    "tpg.run()\n",
    "reg_tpg = np.cumsum(np.sum(tpg.regrets, axis=1))[-1]\n",
    "print(f'TPG final regret: {reg_tpg:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Integration test: run_episodes_with_same_erasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = [\n",
    "    ('SAE', True, 'Scheduled'),\n",
    "    ('SAE', True, 'Feedback', FEEDBACK_ACK_SUCCESS),\n",
    "    ('SAE', True, 'TPG', FEEDBACK_ACK_SUCCESS),\n",
    "]\n",
    "\n",
    "K, M, T, EPISODES = 5, 3, 300, 3\n",
    "eps_vec = np.array([0.3, 0.7, 0.95])\n",
    "\n",
    "results = run_episodes_with_same_erasures(\n",
    "    algs,\n",
    "    iters=T,\n",
    "    k=K,\n",
    "    episodes=EPISODES,\n",
    "    m=M,\n",
    "    var=1,\n",
    "    mu='random',\n",
    "    eps=eps_vec,\n",
    "    base_actions=np.zeros(M, dtype=int),\n",
    "    feedback_mode=[a[3] if len(a)==4 else FEEDBACK_NONE for a in algs],\n",
    "    rng_seed=42,\n",
    ")\n",
    "\n",
    "print('\\n=== Summary ===')\n",
    "for alg, data in results.items():\n",
    "    reg = np.cumsum(np.sum(data['regret'], axis=1))[-1]\n",
    "    print(f\"{data['name']:>15s}: R_T={reg:.1f}, TX={data['avg_tx'][-1]:.0f}, FB={data['avg_fb'][-1]:.0f}\")\n",
    "print('\\nAll good!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scaling test: K=50, M=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_big, M_big, T_big = 50, 4, 2000\n",
    "eps_big = np.array([0.3, 0.6, 0.8, 0.95])\n",
    "alphas_big = calculate_repetitions(eps_big, T_big, m=M_big)\n",
    "print(f'K={K_big}, M={M_big}, T={T_big}, alphas={alphas_big}')\n",
    "\n",
    "results_big = run_episodes_with_same_erasures(\n",
    "    algs,\n",
    "    iters=T_big,\n",
    "    k=K_big,\n",
    "    episodes=2,\n",
    "    m=M_big,\n",
    "    var=1,\n",
    "    mu='random',\n",
    "    eps=eps_big,\n",
    "    base_actions=np.zeros(M_big, dtype=int),\n",
    "    feedback_mode=[a[3] if len(a)==4 else FEEDBACK_NONE for a in algs],\n",
    "    rng_seed=42,\n",
    ")\n",
    "\n",
    "print('\\n=== K=50 Summary ===')\n",
    "for alg, data in results_big.items():\n",
    "    reg = np.cumsum(np.sum(data['regret'], axis=1))[-1]\n",
    "    print(f\"{data['name']:>15s}: R_T={reg:.1f}\")\n",
    "print('K=50 test passed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}