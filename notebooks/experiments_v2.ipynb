{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "## MAB Experiments (Paper Runs)\n",
    "This notebook compares SP2 variants and several TPG variants under shared erasure sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504fb01",
   "metadata": {},
   "outputs": [],
   "source": "import sys, os\nif os.path.basename(os.getcwd()) == 'notebooks':\n    sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom runners import run_episodes_with_same_erasures\nfrom models import (\n    FEEDBACK_BEACON,\n    FEEDBACK_ACK_SUCCESS,\n    FEEDBACK_NONE,\n    FEEDBACK_NACK_ERASE,\n    FEEDBACK_ALL,\n)\n\nnp.set_printoptions(precision=3, suppress=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eps_vector(m, values):\n",
    "    eps1, eps2, eps3, eps4 = values\n",
    "    base = [eps1] * (m // 4) + [eps2] * (m // 4) + [eps3] * (m // 4)\n",
    "    rem = m - 3 * (m // 4)\n",
    "    base += [eps4] * rem\n",
    "    return np.array(base)\n",
    "\n",
    "\n",
    "def summarize(vars_dict, energy_fb=0.1, energy_tx=1.0):\n",
    "    \"\"\"Summarize final regret & energy for a dict returned by run_episodes_with_same_erasures.\"\"\"\n",
    "    rows = []\n",
    "    for alg, data in vars_dict.items():\n",
    "        name = data['name']\n",
    "        reg = np.sum(data['regret'], axis=1)\n",
    "        R_T = np.cumsum(reg)[-1]\n",
    "        TX_T = data['avg_tx'][-1]\n",
    "        FB_T = data['avg_fb'][-1]\n",
    "        E_T = energy_tx * TX_T + energy_fb * FB_T\n",
    "        rows.append({\n",
    "            'alg': name,\n",
    "            'R_T': R_T,\n",
    "            'TX_T': TX_T,\n",
    "            'FB_T': FB_T,\n",
    "            'E_T': E_T,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_multiE(vars_dict, ratios, energy_tx=1.0):\n",
    "    \"\"\"Summarize regret + TX/FB + multiple energy ratios r = E_fb/E_tx.\"\"\"\n",
    "    rows = []\n",
    "    for alg, data in vars_dict.items():\n",
    "        name = data['name']\n",
    "        reg = np.sum(data['regret'], axis=1)\n",
    "        R_T = np.cumsum(reg)[-1]\n",
    "        TX_T = data['avg_tx'][-1]\n",
    "        FB_T = data['avg_fb'][-1]\n",
    "        row = {\n",
    "            'alg': name,\n",
    "            'R_T': R_T,\n",
    "            'TX_T': TX_T,\n",
    "            'FB_T': FB_T,\n",
    "        }\n",
    "        for r in ratios:\n",
    "            row[f'E_T_r{r}'] = energy_tx * TX_T + r * FB_T\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Shared experiment constants\n",
    "ENERGY_TX = 1.0\n",
    "RATIOS = [0.0, 0.1, 1.0]   # r = E_fb / E_tx values we may report in tables\n",
    "RNG_SEED = 12345\n",
    "\n",
    "# Fix global random state so that erasure sequences and random means are reproducible\n",
    "np.random.seed(RNG_SEED)\n",
    "import pickle\n",
    "RESULTS_DIR = os.path.join(os.path.dirname(os.getcwd()), 'results') if os.path.basename(os.getcwd()) == 'notebooks' else './results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to {os.path.abspath(RESULTS_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e41e33",
   "metadata": {},
   "outputs": [],
   "source": "## Epsilon sampling (nominal + hard scenarios)\n# We sample heterogeneous eps vectors once, reproducibly, and reuse them.\n\nMs = [4, 20, 40]\nM_hard = 40  # we only use the hard scenario for M=40\n\nrng_eps = np.random.default_rng(RNG_SEED)\n\ndef sample_eps_nominal(M, rng):\n    \"\"\"\n    Nominal scenario:\n      - first 1/4 from [0.1, 0.5]\n      - second 1/4 from [0.5, 0.8]\n      - third 1/4 from [0.8, 0.95]\n      - last  1/4 from [0.95, 0.999]\n    Then sort.\n    \"\"\"\n    q = M // 4\n    n1 = q\n    n2 = q\n    n3 = q\n    n4 = M - 3*q\n\n    eps1 = rng.uniform(0.1, 0.5, size=n1)\n    eps2 = rng.uniform(0.5, 0.8, size=n2)\n    eps3 = rng.uniform(0.8, 0.95, size=n3)\n    eps4 = rng.uniform(0.95, 0.999, size=n4)\n\n    eps = np.concatenate([eps1, eps2, eps3, eps4])\n    eps.sort()\n    return eps\n\n\ndef sample_eps_hard_from_nominal(M, eps_nominal, rng):\n    \"\"\"\n    Hard scenario for M:\n      - Start from the nominal eps (sorted).\n      - Replace the *first* quarter (lowest 1/4) with fresh samples from [0.5, 0.8].\n      - Keep the remaining 3/4 of the nominal eps.\n      - Sort again.\n    \"\"\"\n    q = M // 4\n    if q == 0:\n        raise ValueError(\"M too small for 'hard' construction.\")\n\n    n1 = q\n    # nominal eps assumed sorted\n    eps_nominal_sorted = np.sort(eps_nominal)\n    eps_rest = eps_nominal_sorted[n1:]  # keep upper 3/4\n\n    eps1_new = rng.uniform(0.5, 0.8, size=n1)\n    eps_hard = np.concatenate([eps1_new, eps_rest])\n    eps_hard.sort()\n    return eps_hard\n\n\n# Precompute and print eps vectors\neps_nominal = {}\neps_hard = {}\n\nprint(\"=== Nominal epsilon vectors ===\")\nfor M in Ms:\n    eps_nominal[M] = sample_eps_nominal(M, rng_eps)\n    print(f\"M={M}, nominal eps:\")\n    print(eps_nominal[M])\n\nprint(\"\\n=== Hard epsilon vector (M=40) ===\")\neps_hard[M_hard] = sample_eps_hard_from_nominal(M_hard, eps_nominal[M_hard], rng_eps)\nprint(f\"M={M_hard}, hard eps:\")\nprint(eps_hard[M_hard])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d62c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm list (clear mapping to modes)\n",
    "# Using ACK-SUCCESS as the chosen feedback scheme for SP2-Feedback and TPG.\n",
    "algs = [\n",
    "    ('SAE', True, 'Scheduled'),                      # SP2 baseline (no feedback)\n",
    "    ('SAE', True, 'Feedback', FEEDBACK_ACK_SUCCESS), # SP2 with feedback (ACK)\n",
    "    ('SAE', True, 'TPG', FEEDBACK_ACK_SUCCESS),      # main TPG (ACK)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plots: color/style mapping\n",
    "colors = {'SP2':'tab:blue', 'SP2-Feedback':'tab:orange', 'TPG':'tab:green'}\n",
    "linestyles = {'SP2':'-', 'SP2-Feedback':':', 'TPG':'--'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ebc0a9",
   "metadata": {},
   "source": [
    "### Quick smoke test (small T)\n",
    "Set `RUN_SMALL` to True to validate wiring without long runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254dd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick smoke test (small T)\n",
    "RUN_SMALL = True\n",
    "\n",
    "if RUN_SMALL:\n",
    "    cfg = {'k':5, 'm':3, 'iters':200, 'episodes':5, 'var':1, 'mu':'random'}\n",
    "    eps_vec = np.array([0.7, 0.9, 0.99])\n",
    "\n",
    "    vars_small = run_episodes_with_same_erasures(\n",
    "        algs,\n",
    "        iters=cfg['iters'],\n",
    "        k=cfg['k'],\n",
    "        episodes=cfg['episodes'],\n",
    "        m=cfg['m'],\n",
    "        var=cfg['var'],\n",
    "        mu=cfg['mu'],\n",
    "        eps=eps_vec,\n",
    "        base_actions=np.random.randint(cfg['k'], size=(cfg['m'],)),\n",
    "        feedback_mode=[a[3] if len(a)==4 else FEEDBACK_NONE for a in algs],\n",
    "        rng_seed=RNG_SEED,\n",
    "    )\n",
    "\n",
    "    print(\"Summary at E_fb=0.1:\")\n",
    "    display(summarize(vars_small, energy_fb=0.1, energy_tx=ENERGY_TX))\n",
    "    print(\"Summary for multiple E_fb/E_tx ratios:\")\n",
    "    display(summarize_multiE(vars_small, RATIOS, energy_tx=ENERGY_TX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee1b59",
   "metadata": {},
   "source": [
    "### Full experiments\n",
    "Toggle `RUN_FULL` to execute paper-scale experiments. Adjust M or epsilon scenarios below if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbbb19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full experiments (paper-scale simulations)\n",
    "# Run once, then reuse in plotting cells.\n",
    "\n",
    "# Reset global seed so full experiments are reproducible regardless of smoke test\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "os.environ['RUN_MAB_PARALLEL'] = '1'  # if helper_methods uses this flag\n",
    "\n",
    "RUN_FULL = True\n",
    "\n",
    "T_FULL = 50000\n",
    "EPISODES_FULL = 100\n",
    "VAR = 1.0\n",
    "MU = 'random'\n",
    "\n",
    "# Global caches\n",
    "full_results = {}      # (M, 'nominal' or 'hard') -> vars_out\n",
    "full_summary_rows = [] # for summary table (at a default E_fb/E_tx, say 0.1)\n",
    "\n",
    "if RUN_FULL:\n",
    "    fb_list = [a[3] if len(a)==4 else FEEDBACK_NONE for a in algs]\n",
    "\n",
    "    for M in Ms:\n",
    "        # --- Nominal scenario ---\n",
    "        eps_vec_nom = eps_nominal[M]\n",
    "        base_actions = np.random.randint(10, size=(M,))\n",
    "        print(f\"Running nominal: M={M}\")\n",
    "        vars_out_nom = run_episodes_with_same_erasures(\n",
    "            algs,\n",
    "            iters=T_FULL,\n",
    "            k=10,\n",
    "            episodes=EPISODES_FULL,\n",
    "            m=M,\n",
    "            var=VAR,\n",
    "            mu=MU,\n",
    "            eps=eps_vec_nom,\n",
    "            base_actions=base_actions,\n",
    "            feedback_mode=fb_list,\n",
    "            rng_seed=RNG_SEED,\n",
    "        )\n",
    "        full_results[(M, 'nominal')] = vars_out_nom\n",
    "\n",
    "        df_nom = summarize(vars_out_nom, energy_fb=0.1, energy_tx=ENERGY_TX)\n",
    "        df_nom.insert(0, 'M', M)\n",
    "        df_nom.insert(1, 'eps_tag', 'nominal')\n",
    "        full_summary_rows.append(df_nom)\n",
    "\n",
    "    # --- Hard scenario only for M=40 ---\n",
    "    M_hard = 40\n",
    "    if M_hard in eps_hard:\n",
    "        eps_vec_hard = eps_hard[M_hard]\n",
    "        base_actions = np.random.randint(10, size=(M_hard,))\n",
    "        print(f\"Running hard: M={M_hard}\")\n",
    "        vars_out_hard = run_episodes_with_same_erasures(\n",
    "            algs,\n",
    "            iters=T_FULL,\n",
    "            k=10,\n",
    "            episodes=EPISODES_FULL,\n",
    "            m=M_hard,\n",
    "            var=VAR,\n",
    "            mu=MU,\n",
    "            eps=eps_vec_hard,\n",
    "            base_actions=base_actions,\n",
    "            feedback_mode=fb_list,\n",
    "            rng_seed=RNG_SEED,\n",
    "        )\n",
    "        full_results[(M_hard, 'hard')] = vars_out_hard\n",
    "\n",
    "        df_hard = summarize(vars_out_hard, energy_fb=0.1, energy_tx=ENERGY_TX)\n",
    "        df_hard.insert(0, 'M', M_hard)\n",
    "        df_hard.insert(1, 'eps_tag', 'hard')\n",
    "        full_summary_rows.append(df_hard)\n",
    "\n",
    "    if full_summary_rows:\n",
    "        full_summary_df = pd.concat(full_summary_rows, ignore_index=True)\n",
    "        print(\"=== Full summary at E_fb/E_tx = 0.1 ===\")\n",
    "        display(full_summary_df)\n",
    "    else:\n",
    "        full_summary_df = None\n",
    "\n",
    "# Convenience caches for plotting\n",
    "cache_nominal = {M: full_results[(M, 'nominal')] for M in Ms if (M, 'nominal') in full_results}\n",
    "cache_hard = full_results.get((40, 'hard'), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pewetxi9hgk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full experiment results to disk\n",
    "save_path = os.path.join(RESULTS_DIR, 'full_results.pkl')\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'full_results': full_results,\n",
    "        'eps_nominal': eps_nominal,\n",
    "        'eps_hard': eps_hard,\n",
    "        'config': {\n",
    "            'T': T_FULL, 'episodes': EPISODES_FULL, 'K': 10,\n",
    "            'VAR': VAR, 'MU': MU, 'RNG_SEED': RNG_SEED,\n",
    "        }\n",
    "    }, f)\n",
    "print(f\"Saved full results to {os.path.abspath(save_path)}\")\n",
    "\n",
    "# Also save summary table\n",
    "full_summary_df.to_csv(os.path.join(RESULTS_DIR, 'full_summary.csv'), index=False)\n",
    "print(\"Saved summary CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5767a",
   "metadata": {},
   "source": [
    "### Feedback scheme sweep (TPG and SP2-Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feedback scheme sweep (SP2-Feedback and TPG)\n",
    "\n",
    "M_sweep = 40\n",
    "T_sweep = 20000      # shorter horizon for ablation; can set = T_FULL if desired\n",
    "EPISODES_sweep = 20  # fewer episodes for ablation\n",
    "\n",
    "# Use the same \"hard\" epsilon vector as in the main M=40 hard experiment\n",
    "if 'eps_hard' not in globals() or M_sweep not in eps_hard:\n",
    "    raise RuntimeError(\"eps_hard not defined for M_sweep. Run the eps sampling cell first.\")\n",
    "eps_vec_sweep = eps_hard[M_sweep]\n",
    "\n",
    "# Reproducible base actions for this sweep\n",
    "rng_base = np.random.default_rng(RNG_SEED + 10)\n",
    "base_actions_sweep = rng_base.integers(10, size=(M_sweep,))\n",
    "\n",
    "feedback_modes = [FEEDBACK_ALL, FEEDBACK_BEACON, FEEDBACK_ACK_SUCCESS, FEEDBACK_NACK_ERASE]\n",
    "\n",
    "# Algorithms: SP2-Feedback and TPG; feedback_mode overridden per sweep\n",
    "alg_feedback = [\n",
    "    ('SAE', True, 'Feedback', None),  # SP2-Feedback; fb override set below\n",
    "    ('SAE', True, 'TPG', None),       # TPG; fb override set below\n",
    "]\n",
    "\n",
    "feedback_sweep_rows = []\n",
    "\n",
    "for fb_mode in feedback_modes:\n",
    "    # Attach the chosen feedback mode as the 4th element in each alg tuple\n",
    "    algs_sweep = [(a[0], a[1], a[2], fb_mode) for a in alg_feedback]\n",
    "\n",
    "    vars_sweep = run_episodes_with_same_erasures(\n",
    "        algs_sweep,\n",
    "        iters=T_sweep,\n",
    "        k=10,\n",
    "        episodes=EPISODES_sweep,\n",
    "        m=M_sweep,\n",
    "        var=VAR,\n",
    "        mu=MU,\n",
    "        eps=eps_vec_sweep,\n",
    "        base_actions=base_actions_sweep,\n",
    "        rng_seed=RNG_SEED,\n",
    "    )\n",
    "\n",
    "    # Summarize for multiple E_fb/E_tx ratios (RATIOS) at this sweep setting\n",
    "    df = summarize_multiE(vars_sweep, RATIOS, energy_tx=ENERGY_TX)\n",
    "    df.insert(0, 'feedback_mode', fb_mode)\n",
    "    feedback_sweep_rows.append(df)\n",
    "\n",
    "if feedback_sweep_rows:\n",
    "    feedback_sweep_df = pd.concat(feedback_sweep_rows, ignore_index=True)\n",
    "    print(\"=== Feedback sweep summary (multiple E_fb/E_tx ratios) ===\")\n",
    "    display(feedback_sweep_df)\n",
    "else:\n",
    "    feedback_sweep_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0e088",
   "metadata": {},
   "source": [
    "### Regret vs time (M=4,20,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2uqcjch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load saved results (skip this cell if you just ran the experiments above) ---\n",
    "# Uncomment the block below to reload from disk instead of re-running experiments.\n",
    "\n",
    "# load_path = os.path.join(RESULTS_DIR, 'full_results.pkl')\n",
    "# with open(load_path, 'rb') as f:\n",
    "#     saved = pickle.load(f)\n",
    "# full_results = saved['full_results']\n",
    "# eps_nominal = saved['eps_nominal']\n",
    "# eps_hard = saved['eps_hard']\n",
    "# cache_nominal = {M: full_results[(M, 'nominal')] for M in Ms if (M, 'nominal') in full_results}\n",
    "# cache_hard = full_results.get((40, 'hard'), None)\n",
    "# print(f\"Loaded results from {load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd84067",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regret vs time for M=4,20,40 (nominal eps)\n",
    "\n",
    "if not cache_nominal:\n",
    "    raise RuntimeError(\"cache_nominal is empty. Run the full experiments cell first.\")\n",
    "\n",
    "Ms_plot = [4, 20, 40]\n",
    "subplot_names = ['(a)', '(b)', '(c)']\n",
    "\n",
    "# --- Font size (ADJUST HERE) ---\n",
    "FONT_SIZE = 14       # axis labels, legend\n",
    "TICK_SIZE = 12       # tick labels\n",
    "TITLE_SIZE = 14      # subplot titles (if used)\n",
    "\n",
    "dpi = 300\n",
    "linewidth = 2.5\n",
    "x_upper = 1e4\n",
    "y_upper = 8500\n",
    "\n",
    "clrs = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "lstyles = [\"solid\", \":\", \"--\"]\n",
    "alg_order = [\"SP2\", \"SP2-Feedback\", \"TPG\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5), dpi=dpi)\n",
    "\n",
    "for subplot_idx, M in enumerate(Ms_plot):\n",
    "    ax = axes[subplot_idx]\n",
    "    vars_plot = cache_nominal[M]\n",
    "\n",
    "    name_to_data = {}\n",
    "    for alg in algs:\n",
    "        data = vars_plot[alg]\n",
    "        name_to_data[data['name']] = data\n",
    "\n",
    "    for i, alg_name in enumerate(alg_order):\n",
    "        data = name_to_data[alg_name]\n",
    "        reg = np.sum(data['regret'], axis=1)\n",
    "        cum_reg = np.cumsum(reg)\n",
    "        t_axis = np.arange(1, cum_reg.shape[0] + 1)\n",
    "\n",
    "        ax.plot(t_axis, cum_reg, linewidth=linewidth,\n",
    "                color=clrs[i], linestyle=lstyles[i], label=alg_name)\n",
    "\n",
    "    if subplot_idx == 0:\n",
    "        ax.set_ylabel(\"Regret ($R_t$)\", fontsize=FONT_SIZE)\n",
    "\n",
    "    ax.set_xlabel(\"Rounds ($t$)\\n\" + subplot_names[subplot_idx], fontsize=FONT_SIZE)\n",
    "    ax.ticklabel_format(style='scientific', axis='both', scilimits=(0, 1))\n",
    "    ax.tick_params(labelsize=TICK_SIZE)\n",
    "    ax.xaxis.offsetText.set_fontsize(TICK_SIZE)\n",
    "    ax.yaxis.offsetText.set_fontsize(TICK_SIZE)\n",
    "    ax.set_xlim([-10, x_upper])\n",
    "    if y_upper is not None:\n",
    "        ax.set_ylim([0, y_upper])\n",
    "    ax.legend(fontsize=FONT_SIZE - 2)\n",
    "    ax.grid(linewidth=0.15)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig_path = os.path.join(RESULTS_DIR, 'k10_m4-20-40_nominal_jsait.png')\n",
    "fig.savefig(fig_path, dpi=dpi, bbox_inches='tight')\n",
    "print(f\"Saved: {fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57d4765",
   "metadata": {},
   "source": [
    "### Regret vs time (hard instance, M=40, high eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c080df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regret vs time (M=40, hard eps)\n",
    "\n",
    "if cache_hard is None:\n",
    "    raise RuntimeError(\"cache_hard is empty. Run the full experiments cell first.\")\n",
    "\n",
    "dpi = 300\n",
    "linewidth = 2.5\n",
    "x_upper = 1e4\n",
    "y_upper = 8900\n",
    "\n",
    "clrs = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "lstyles = [\"solid\", \":\", \"--\"]\n",
    "alg_order = [\"SP2\", \"SP2-Feedback\", \"TPG\"]\n",
    "\n",
    "vars_plot = cache_hard\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.5), dpi=dpi)\n",
    "\n",
    "name_to_data = {}\n",
    "for alg in algs:\n",
    "    data = vars_plot[alg]\n",
    "    name_to_data[data['name']] = data\n",
    "\n",
    "for i, alg_name in enumerate(alg_order):\n",
    "    data = name_to_data[alg_name]\n",
    "    reg = np.sum(data['regret'], axis=1)\n",
    "    cum_reg = np.cumsum(reg)\n",
    "    t_axis = np.arange(1, cum_reg.shape[0] + 1)\n",
    "\n",
    "    ax.plot(t_axis, cum_reg, linewidth=linewidth,\n",
    "            color=clrs[i], linestyle=lstyles[i], label=alg_name)\n",
    "\n",
    "ax.set_xlabel(\"Rounds ($t$)\", fontsize=FONT_SIZE)\n",
    "ax.set_ylabel(\"Regret ($R_t$)\", fontsize=FONT_SIZE)\n",
    "ax.ticklabel_format(style='scientific', axis='both', scilimits=(0, 1))\n",
    "ax.tick_params(labelsize=TICK_SIZE)\n",
    "ax.xaxis.offsetText.set_fontsize(TICK_SIZE)\n",
    "ax.yaxis.offsetText.set_fontsize(TICK_SIZE)\n",
    "ax.set_xlim([-10, x_upper])\n",
    "if y_upper is not None:\n",
    "    ax.set_ylim([0, y_upper])\n",
    "ax.legend(fontsize=FONT_SIZE - 2)\n",
    "ax.grid(linewidth=0.15)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig_path = os.path.join(RESULTS_DIR, 'k10_m40_eps_hard_jsait.png')\n",
    "fig.savefig(fig_path, dpi=dpi, bbox_inches='tight')\n",
    "print(f\"Saved: {fig_path}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}